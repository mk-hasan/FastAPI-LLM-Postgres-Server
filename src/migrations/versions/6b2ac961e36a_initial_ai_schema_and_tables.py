"""Initial AI schema and tables

Revision ID: 6b2ac961e36a
Revises: 
Create Date: 2025-07-17 18:59:18.485236

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '6b2ac961e36a'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # 1. Create the schema first
    op.execute(sa.schema.CreateSchema('db_ai', if_not_exists=True))

    # 2. Create the llm_cache table within the 'db_ai' schema
    op.create_table(
        'llm_cache',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('prompt_hash', sa.String(), nullable=False),
        sa.Column('prompt_text', sa.Text(), nullable=False),
        sa.Column('llm_provider', sa.String(), nullable=False),
        sa.Column('generated_text', sa.Text(), nullable=False),
        sa.Column('cached_at', sa.DateTime(), server_default=sa.text('now()'), nullable=True), # Use server_default for func.now()
        sa.Column('expires_at', sa.DateTime(), nullable=True),
        sa.PrimaryKeyConstraint('id'),
        schema='db_ai' # IMPORTANT: Ensure this matches the schema name
    )
    op.create_index(op.f('ix_db_ai_llm_cache_id'), 'llm_cache', ['id'], unique=False, schema='db_ai')
    op.create_index(op.f('ix_db_ai_llm_cache_prompt_hash'), 'llm_cache', ['prompt_hash'], unique=True, schema='db_ai')


    # 3. Create the user_data table within the 'db_ai' schema
    op.create_table(
        'user_data',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(), nullable=False),
        sa.Column('email', sa.String(), nullable=False),
        sa.Column('is_active', sa.Boolean(), nullable=True, server_default=sa.text('true')), # For Boolean default
        sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=True),
        sa.PrimaryKeyConstraint('id'),
        schema='db_ai' # IMPORTANT: Ensure this matches the schema name
    )
    op.create_index(op.f('ix_db_ai_user_data_email'), 'user_data', ['email'], unique=True, schema='db_ai')
    op.create_index(op.f('ix_db_ai_user_data_id'), 'user_data', ['id'], unique=False, schema='db_ai')
    op.create_index(op.f('ix_db_ai_user_data_name'), 'user_data', ['name'], unique=False, schema='db_ai')

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Drop tables first (in reverse order of creation)
    op.drop_index(op.f('ix_db_ai_user_data_name'), table_name='user_data', schema='db_ai')
    op.drop_index(op.f('ix_db_ai_user_data_id'), table_name='user_data', schema='db_ai')
    op.drop_index(op.f('ix_db_ai_user_data_email'), table_name='user_data', schema='db_ai')
    op.drop_table('user_data', schema='db_ai')

    op.drop_index(op.f('ix_db_ai_llm_cache_prompt_hash'), table_name='llm_cache', schema='db_ai')
    op.drop_index(op.f('ix_db_ai_llm_cache_id'), table_name='llm_cache', schema='db_ai')
    op.drop_table('llm_cache', schema='db_ai')

    # Then drop the schema
    op.execute(sa.schema.DropSchema('db_ai', if_exists=True, cascade=True))
    # ### end Alembic commands ###